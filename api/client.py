# Web app client side to interect with LLM API generated by app.py

import requests
import streamlit as st

def get_llm_response(inpput_text):
    response = requests.post("http://localhost:8000/essay/invoke",
                             json = {"input":{"topic":input_text}})
    return response.json()["output"]
    # For openai return response has another key ["content"]

# Streamlit UI on Client side
st.title("Langchain with Llama2 API")
input_text = st.text_input("Enter the topic for the essay")

if input_text:
    st.write(get_llm_response(input_text))

